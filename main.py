import streamlit as st
from audiorecorder import audiorecorder
import io

from utils import add_vertical_space, unique_audio_filename, upload_file

st.set_page_config("Data Collection", ":material/home:")


QUESTIONS = [
    {"title": "Ch·ªØ c√°i E", "id": "E"},
    {"title": "Ch·ªØ c√°i H", "id": "H"},
    {"title": "Ch·ªØ c√°i i", "id": "i"},
    {"title": "Ch·ªØ c√°i L", "id": "L"},
    {"title": "Ch·ªØ c√°i N", "id": "N"},
    {"title": "Ch·ªØ c√°i ∆†", "id": "∆†"},
    {"title": "Ch·ªØ c√°i U", "id": "U"},
    {"title": "Ch·ªØ c√°i V", "id": "V"},
]
N_QUESTIONS = len(QUESTIONS)


def next_step():
    st.session_state["step"] += 1


@st.fragment
def show_greeting():
    st.subheader("C·∫£m ∆°n b·∫°n ƒë√£ gi√∫p!")
    add_vertical_space(1)

    st.write(
        "T·ªõ ƒëang c·∫ßn thu th·∫≠p data gi·ªçng n√≥i v·ªÅ 8 ch·ªØ c√°i trong b·∫£ng ch·ªØ c√°i ti·∫øng Vi·ªát ƒë·ªÉ l√†m nghi√™n c·ª©u c√° nh√¢n, h√£y gi√∫p t·ªõ nh√©!"
    )
    st.write(
        "Y√™n t√¢m l√† m·ªçi d·ªØ li·ªáu t·ªõ s·∫Ω b·∫£o m·∫≠t v√† kh√¥ng c√≥ g√¨ l√† nguy hi·ªÉm h·∫øt ƒë√¢u ·∫°."
    )
    st.write(
        "H√£y ·∫•n b·∫Øt ƒë·∫ßu v√† gi√∫p t·ªõ thu √¢m c√°c ch·ªØ c√°i, gi√∫p t·ªõ ƒë·ªçc ch√≠nh x√°c r√µ r√†ng t·ª´ng ch·ªØ nhaaaa"
    )
    st.markdown("**L∆∞u √Ω:**")
    left_col, right_col = st.columns(2, border=True)
    left_col.markdown("![guideline](app/static/mic.png)")
    right_col.markdown("![guideline](app/static/audio_recorder.png)")

    add_vertical_space(1)
    if st.button(label="B·∫Øt ƒë·∫ßu", type="primary"):
        next_step()
        st.rerun()


@st.fragment
def show_question(question):
    question_title = question["title"]
    question_id = question["id"]

    st.subheader(f"{st.session_state['step']}/{len(QUESTIONS)}. {question_title}")
    add_vertical_space(1)

    audio = audiorecorder(
        "",  # "·∫§n ƒë·ªÉ b·∫Øt ƒë·∫ßu ghi √¢m",
        "",  # "·∫§n ƒë·ªÉ d·ª´ng l·∫°i",
        key=question_id,
    )

    if len(audio) > 0:
        st.info(
            "H√£y gi√∫p t·ªõ check l·∫°i ph√°t √¢m xem ƒë√£ ƒë√∫ng v√† r√µ r√†ng ch∆∞a nh√© ·∫°! N·∫øu ch∆∞a ƒë∆∞·ª£c th√¨ h√£y ghi √¢m l·∫°i gi√∫p t·ªõ nha ·∫°!!",
            icon="‚ÑπÔ∏è",
        )
        st.audio(audio.export().read())

    add_vertical_space(2)
    if st.button(label="√Çm ti·∫øp theo", type="primary"):
        if len(audio) > 0:
            with st.spinner("Uploading..."):
                audio_buffer = io.BytesIO()
                audio.export(audio_buffer, format="wav", parameters=["-ar", str(16000)])
                upload_file(audio_buffer.getvalue(), unique_audio_filename(question_id))
            next_step()
            st.rerun()
        else:
            st.error("Ch∆∞a ƒë∆∞·ª£c r·ªìi, gi√∫p t·ªõ thu √¢m l·∫°i nha", icon="üö®")


@st.fragment
def show_thankyou():
    st.subheader("Done!")
    add_vertical_space(1)
    st.write(
        "C·∫£m ∆°n r·∫•t nhi·ªÅu v√¨ ƒë√£ d√†nh th·ªùi gian gi√∫p t·ªõ, ch√∫c c·∫≠u nhi·ªÅu s·ª©c kho·∫ª nha!!"
    )


st.title("Thu th·∫≠p d·ªØ li·ªáu")

if "step" not in st.session_state:
    st.session_state["step"] = 0

with st.container(border=True):
    if st.session_state["step"] == 0:
        show_greeting()
    elif st.session_state["step"] <= N_QUESTIONS:
        question_idx = st.session_state["step"] - 1
        show_question(QUESTIONS[question_idx])
    else:
        show_thankyou()
